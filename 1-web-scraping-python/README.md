# Web Scraping

## DescriÃ§Ã£o
Este projeto implementa um sistema automatizado de web scraping projetado para extrair, baixar e comprimir documentos PDF de sites especÃ­ficos.

## Funcionalidades
- **Web Scraping**: Extrai links para documentos PDF de URLs especÃ­ficas
- **Download AutomÃ¡tico**: Baixa todos os arquivos PDF identificados
- **CompressÃ£o**: Compacta os arquivos baixados em um arquivo ZIP
- **Tratamento Robusto de Erros**: Inclui tratamento abrangente de erros para problemas de rede, erros HTTP e operaÃ§Ãµes com arquivos
- **Registro Detalhado**: Registra todas as operaÃ§Ãµes tanto no console quanto em arquivos de log para monitoramento e depuraÃ§Ã£o

### Estrutura de Pastas

```
ğŸ“ 1-web-scraping-python/
â”‚
â”œâ”€â”€ ğŸ“„ README.md                 # DocumentaÃ§Ã£o do projeto
â”œâ”€â”€ ğŸ“„ requirements.txt          # DependÃªncias do projeto
â”œâ”€â”€ ğŸ“„ .gitignore                # Arquivos ignorados pelo Git
â”‚
â”œâ”€â”€ ğŸ“ src/                      # CÃ³digo fonte principal
â”‚   â”œâ”€â”€ ğŸ“„ config.py             # ConfiguraÃ§Ãµes do projeto
â”‚   â”œâ”€â”€ ğŸ“„ main.py               # Script principal de execuÃ§Ã£o
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ scraping/             # MÃ³dulos de scraping
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ __init__.py       # Define os mÃ³dulos disponÃ­veis
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ scraper.py        # ExtraÃ§Ã£o de links de PDFs
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ downloader.py     # Download de arquivos
â”‚   â”‚   â””â”€â”€ ğŸ“„ compressor.py     # CompressÃ£o de arquivos
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ utils/                # UtilitÃ¡rios
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ __init__.py       # Define os mÃ³dulos disponÃ­veis
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ error_handler.py  # Tratamento de erros
â”‚   â”‚   â””â”€â”€ ğŸ“„ logger.py         # ConfiguraÃ§Ã£o de logs
â”‚   â”‚
â”‚   â””â”€â”€ ğŸ“ downloads/            # Arquivos baixados (criado em runtime)
â”‚       â””â”€â”€ ğŸ“„ (arquivos PDFs)   # PDFs baixados
â”‚
â”œâ”€â”€ ğŸ“ tests/                    # Testes unitÃ¡rios
â”‚   â”œâ”€â”€ ğŸ“„ __init__.py           # Define os mÃ³dulos de teste
â”‚   â”œâ”€â”€ ğŸ“„ test_scraper.py       # Testes para o mÃ³dulo scraper
â”‚   â”œâ”€â”€ ğŸ“„ test_downloader.py    # Testes para o mÃ³dulo downloader
â”‚   â””â”€â”€ ğŸ“„ test_compressor.py    # Testes para o mÃ³dulo compressor
â”‚
â””â”€â”€ ğŸ“ logs/                     # Logs de execuÃ§Ã£o
    â””â”€â”€ ğŸ“„ scraper_*.log         # Arquivos de log com timestamp
```

## InstalaÃ§Ã£o
1. Clone o repositÃ³rio:
   ```bash
   git clone https://github.com/MenossiJose/Intuitive-Care.git
   cd web-scraping-python
   ```
2. Crie um ambiente virtual:
   ```bash
   python -m venv venv
   # No Windows
   venv\Scripts\activate
   # No macOS/Linux
   source venv/bin/activate
   ```
3. Instale as dependÃªncias necessÃ¡rias:
   ```bash
   pip install -r requirements.txt
   ```

## Uso
Execute o script principal para iniciar o processo de scraping:
```bash
python src/main.py
```
Isso irÃ¡:
1. Extrair links de PDF da URL configurada
2. Baixar os arquivos PDF para o diretÃ³rio de downloads
3. Comprimir os arquivos em anexos.zip

## ConfiguraÃ§Ã£o
O comportamento do projeto pode ser configurado em config.py:
- **URL**: A URL do site para fazer scraping
- **DOWNLOAD_DIR**: DiretÃ³rio onde os arquivos baixados serÃ£o salvos
- **ZIP_NAME**: Nome do arquivo ZIP compactado
- **USER_AGENT**: User-agent do navegador para usar nas requisiÃ§Ãµes

## Testes
Execute o conjunto de testes com:
```bash
pytest tests/
```
Ou teste componentes especÃ­ficos:
```bash
pytest tests/test_scraper.py
pytest tests/test_downloader.py
pytest tests/test_compressor.py
```
